{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f278d7fb",
   "metadata": {},
   "source": [
    "# DS3000 Baseline Modeling\n",
    "\n",
    "This notebook documents the Milestone 3 **baseline models** for our inverter thermal-safety problem.  \n",
    "We work with pre-cleaned **1 Hz inverter telemetry** and construct two simple reference models:\n",
    "\n",
    "1. **Logistic regression** with class-balancing to detect imminent **overheating events**.\n",
    "2. **Ridge regression** to forecast the **30-second hot-spot temperature delta** (ΔT₃₀s) as a short‑horizon proxy for thermal risk.\n",
    "\n",
    "The goal here is **not** to find the best possible model, but to:\n",
    "\n",
    "- Define a **reproducible baseline pipeline** using scikit‑learn.\n",
    "- Make all feature/label choices explicit and documented.\n",
    "- Produce metrics that later, more complex models (trees, ensembles, deep nets, etc.) must **beat** to be considered useful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03e3c287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /Users/omarramadan/Desktop/Western_Stuff/2025-26/SE3000 - Intro to Machine Learning/GroupProject/DS3000-Battery-Analyzer/src/notebooks/clean/inverter_labeled_1hz.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dc_raw_sample_count</th>\n",
       "      <th>inv_control_board_temp_count</th>\n",
       "      <th>inv_control_board_temp_max</th>\n",
       "      <th>inv_control_board_temp_mean</th>\n",
       "      <th>inv_control_board_temp_min</th>\n",
       "      <th>inv_coolant_temp_count</th>\n",
       "      <th>inv_coolant_temp_max</th>\n",
       "      <th>inv_coolant_temp_mean</th>\n",
       "      <th>inv_coolant_temp_min</th>\n",
       "      <th>inv_dc_bus_current_count</th>\n",
       "      <th>...</th>\n",
       "      <th>inv_phase_c_current_count</th>\n",
       "      <th>inv_phase_c_current_max</th>\n",
       "      <th>inv_phase_c_current_mean</th>\n",
       "      <th>inv_phase_c_current_min</th>\n",
       "      <th>phase_raw_sample_count</th>\n",
       "      <th>temps_raw_sample_count</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>overheat_label</th>\n",
       "      <th>inv_hot_spot_temp_future</th>\n",
       "      <th>delta_T_30s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.9250</td>\n",
       "      <td>29.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.95000</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2025-06-03 18:56:10</td>\n",
       "      <td>0</td>\n",
       "      <td>31.25</td>\n",
       "      <td>29.30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.3900</td>\n",
       "      <td>30.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.21000</td>\n",
       "      <td>2.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>-0.07967</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2025-06-03 18:56:11</td>\n",
       "      <td>0</td>\n",
       "      <td>31.34</td>\n",
       "      <td>28.13000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>30.7100</td>\n",
       "      <td>30.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.07000</td>\n",
       "      <td>4.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>-0.00133</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2025-06-03 18:56:12</td>\n",
       "      <td>0</td>\n",
       "      <td>31.40</td>\n",
       "      <td>25.33000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.8625</td>\n",
       "      <td>30.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>8.99375</td>\n",
       "      <td>7.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.01317</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2025-06-03 18:56:13</td>\n",
       "      <td>0</td>\n",
       "      <td>31.50</td>\n",
       "      <td>22.50625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.8900</td>\n",
       "      <td>30.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>11.58000</td>\n",
       "      <td>10.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>-0.08500</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2025-06-03 18:56:14</td>\n",
       "      <td>0</td>\n",
       "      <td>31.52</td>\n",
       "      <td>19.94000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dc_raw_sample_count  inv_control_board_temp_count  \\\n",
       "0                  4.0                           4.0   \n",
       "1                 10.0                          10.0   \n",
       "2                 10.0                          10.0   \n",
       "3                 10.0                           8.0   \n",
       "4                 10.0                          10.0   \n",
       "\n",
       "   inv_control_board_temp_max  inv_control_board_temp_mean  \\\n",
       "0                        30.0                      29.9250   \n",
       "1                        30.5                      30.3900   \n",
       "2                        30.8                      30.7100   \n",
       "3                        31.0                      30.8625   \n",
       "4                        31.0                      30.8900   \n",
       "\n",
       "   inv_control_board_temp_min  inv_coolant_temp_count  inv_coolant_temp_max  \\\n",
       "0                        29.9                     4.0                   2.1   \n",
       "1                        30.2                    10.0                   4.3   \n",
       "2                        30.6                    10.0                   7.5   \n",
       "3                        30.7                     8.0                  10.1   \n",
       "4                        30.8                    10.0                  12.7   \n",
       "\n",
       "   inv_coolant_temp_mean  inv_coolant_temp_min  inv_dc_bus_current_count  ...  \\\n",
       "0                1.95000                   1.8                       4.0  ...   \n",
       "1                3.21000                   2.3                      10.0  ...   \n",
       "2                6.07000                   4.6                      10.0  ...   \n",
       "3                8.99375                   7.8                      10.0  ...   \n",
       "4               11.58000                  10.4                      10.0  ...   \n",
       "\n",
       "   inv_phase_c_current_count  inv_phase_c_current_max  \\\n",
       "0                        4.0                   0.2000   \n",
       "1                       10.0                   0.0833   \n",
       "2                       10.0                   0.2000   \n",
       "3                       10.0                   0.2250   \n",
       "4                       10.0                   0.1400   \n",
       "\n",
       "   inv_phase_c_current_mean  inv_phase_c_current_min  phase_raw_sample_count  \\\n",
       "0                   0.09375                     0.04                     4.0   \n",
       "1                  -0.07967                    -0.52                    10.0   \n",
       "2                  -0.00133                    -0.22                    10.0   \n",
       "3                   0.01317                    -0.14                    10.0   \n",
       "4                  -0.08500                    -0.30                    10.0   \n",
       "\n",
       "   temps_raw_sample_count           timestamp  overheat_label  \\\n",
       "0                     4.0 2025-06-03 18:56:10               0   \n",
       "1                    10.0 2025-06-03 18:56:11               0   \n",
       "2                    10.0 2025-06-03 18:56:12               0   \n",
       "3                     9.0 2025-06-03 18:56:13               0   \n",
       "4                    10.0 2025-06-03 18:56:14               0   \n",
       "\n",
       "   inv_hot_spot_temp_future  delta_T_30s  \n",
       "0                     31.25     29.30000  \n",
       "1                     31.34     28.13000  \n",
       "2                     31.40     25.33000  \n",
       "3                     31.50     22.50625  \n",
       "4                     31.52     19.94000  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports, path setup, and label engineering\n",
    "# - Import core Python, pandas/numpy, plotting, and scikit‑learn utilities.\n",
    "# - Locate the cleaned 1 Hz inverter CSV in the `clean/` data directory.\n",
    "# - Load the time‑ordered dataframe and ensure it is sorted by `timestamp`.\n",
    "# - If needed, create convenience label columns:\n",
    "#     * `overheat_label` (binary) from a 65 °C hot‑spot threshold.\n",
    "#     * `inv_hot_spot_temp_future` (30 s look‑ahead temperature).\n",
    "#     * `delta_T_30s` (future minus current hot‑spot temperature).\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    ")\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "CWD = Path.cwd()\n",
    "if (CWD / 'clean').exists():\n",
    "    CLEAN_DIR = CWD / 'clean'\n",
    "elif (CWD / 'src' / 'notebooks' / 'clean').exists():\n",
    "    CLEAN_DIR = CWD / 'src' / 'notebooks' / 'clean'\n",
    "elif (CWD / 'src' / 'clean').exists():\n",
    "    CLEAN_DIR = CWD / 'src' / 'clean'\n",
    "else:\n",
    "    raise FileNotFoundError('Could not locate clean/ directory')\n",
    "\n",
    "PRIMARY_PATH = CLEAN_DIR / 'inverter_labeled_1hz.csv'\n",
    "FALLBACK_PATH = CLEAN_DIR / 'inverter_merged_1hz.csv'\n",
    "DATA_PATH = PRIMARY_PATH if PRIMARY_PATH.exists() else FALLBACK_PATH\n",
    "\n",
    "print('Loading', DATA_PATH)\n",
    "df = pd.read_csv(DATA_PATH, parse_dates=['timestamp']).sort_values('timestamp')\n",
    "\n",
    "if 'overheat_label' not in df.columns:\n",
    "    df['overheat_label'] = (df['inv_hot_spot_temp_mean'] >= 65).astype(int)\n",
    "if 'inv_hot_spot_temp_future' not in df.columns:\n",
    "    df['inv_hot_spot_temp_future'] = df['inv_hot_spot_temp_mean'].shift(-30)\n",
    "if 'delta_T_30s' not in df.columns:\n",
    "    df['delta_T_30s'] = df['inv_hot_spot_temp_future'] - df['inv_hot_spot_temp_mean']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a5de0f",
   "metadata": {},
   "source": [
    "## 1. Feature Selection & Chronological Split\n",
    "\n",
    "We start by defining which columns are allowed as **inputs** and how we split the data into train/test sets.\n",
    "\n",
    "- We restrict predictors to telemetry columns ending in **`_mean`** (e.g., temperatures, voltages, currents).  \n",
    "  These are relatively smooth, aggregated signals that are easier to model and less noisy than raw samples.\n",
    "- We **explicitly exclude** columns that directly encode the target:\n",
    "  - `inv_hot_spot_temp_mean` (current hot-spot temperature)\n",
    "  - `inv_hot_spot_temp_future` (look‑ahead hot-spot temperature)\n",
    "  - `delta_T_30s` (the 30-second temperature delta)\n",
    "- Any row that is missing either the features or the label(s) is dropped with `dropna`.  \n",
    "  This keeps the training set internally consistent and avoids silent NaN propagation.\n",
    "\n",
    "For the split:\n",
    "\n",
    "- We perform an **80/20 chronological split** using the row index (first ~80% for training, last ~20% for testing).\n",
    "- We do **not shuffle** the data, because time ordering matters and random shuffling would leak information from the future into the past.\n",
    "- The same feature set is later reused for both:\n",
    "  - the **classification** task (`overheat_label`), and\n",
    "  - the **regression** task (`delta_T_30s`).\n",
    "\n",
    "This gives us a clean, time‑respecting partition that we can reuse across multiple models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "524a7134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 11\n",
      "Train rows: 2658 | Test rows: 665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['inv_control_board_temp_mean',\n",
       " 'inv_coolant_temp_mean',\n",
       " 'inv_dc_bus_current_mean',\n",
       " 'inv_dc_bus_voltage_mean',\n",
       " 'inv_gate_driver_board_temp_mean',\n",
       " 'inv_module_a_temp_mean',\n",
       " 'inv_module_b_temp_mean',\n",
       " 'inv_module_c_temp_mean',\n",
       " 'inv_phase_a_current_mean',\n",
       " 'inv_phase_b_current_mean']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature selection and chronological train/test split\n",
    "# - Build `feature_cols` from all `_mean` telemetry columns, excluding target‑related fields.\n",
    "# - Drop any rows that are missing features or labels to keep the modeling dataframe clean.\n",
    "# - Perform an 80/20 **chronological** split (no shuffling) to avoid future‑to‑past leakage.\n",
    "# - Extract `X_train`, `X_test` and the `overheat_label` targets for the classification baseline.\n",
    "# - The same feature set will later be reused for the regression target `delta_T_30s`.\n",
    "\n",
    "exclude_cols = {'inv_hot_spot_temp_mean', 'inv_hot_spot_temp_future', 'delta_T_30s'}\n",
    "feature_cols = [c for c in df.columns if c.endswith('_mean') and c not in exclude_cols]\n",
    "\n",
    "model_df = df.dropna(subset=feature_cols + ['overheat_label'])\n",
    "split_idx = int(len(model_df) * 0.8)\n",
    "train_df = model_df.iloc[:split_idx]\n",
    "test_df = model_df.iloc[split_idx:]\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "X_test = test_df[feature_cols]\n",
    "y_train = train_df['overheat_label']\n",
    "y_test = test_df['overheat_label']\n",
    "\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(f\"Train rows: {len(train_df)} | Test rows: {len(test_df)}\")\n",
    "print('First few features:', feature_cols[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d8f018",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression Baseline\n",
    "\n",
    "Our first model is a **logistic regression classifier** that predicts whether an overheat event is about to occur.\n",
    "\n",
    "Pipeline details:\n",
    "\n",
    "- **StandardScaler**: each feature is standardized to zero mean and unit variance.  \n",
    "  This is important for logistic regression, which is sensitive to the scale of the inputs.\n",
    "- **LogisticRegression** with `class_weight='balanced'`:\n",
    "  - Overheating events are typically **rare** compared to normal operation.\n",
    "  - Using a balanced class weight up‑weights the minority (overheat) class, so the model does not simply predict “no overheat” all the time.\n",
    "\n",
    "Training & evaluation:\n",
    "\n",
    "- The model is trained on the chronologically earlier **train split** and evaluated on the held‑out **test split**.\n",
    "- We compute:\n",
    "  - `classification_report` (precision, recall, F1‑score per class),\n",
    "  - **ROC AUC** using the predicted probabilities for the positive class,\n",
    "  - the **confusion matrix**, which shows the trade‑off between missed overheat events (false negatives) and false alarms (false positives).\n",
    "\n",
    "This model serves as a **simple, interpretable baseline**; any future classifier should beat its ROC AUC and F1‑score to justify added complexity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00ee7d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.998     0.857     0.922       602\n",
      "           1      0.419     0.984     0.588        63\n",
      "\n",
      "    accuracy                          0.869       665\n",
      "   macro avg      0.708     0.921     0.755       665\n",
      "weighted avg      0.943     0.869     0.891       665\n",
      "\n",
      "ROC AUC: 0.9937509887676\n",
      "Confusion matrix: [[516  86]\n",
      " [  1  62]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression baseline: training and evaluation\n",
    "# - Wrap preprocessing and the classifier in a scikit‑learn `Pipeline`:\n",
    "#     * `StandardScaler` for feature normalization.\n",
    "#     * `LogisticRegression` with `class_weight='balanced'` to handle class imbalance.\n",
    "# - Fit on the training portion of the time series.\n",
    "# - Use the trained model to obtain class predictions and probabilities on the test set.\n",
    "# - Report precision/recall/F1 per class, ROC‑AUC, and the confusion matrix\n",
    "#   as reference metrics for future, more advanced classifiers.\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(max_iter=1000, class_weight='balanced')),\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "print('ROC AUC:', roc_auc_score(y_test, y_prob))\n",
    "print('Confusion matrix:'\n",
    ", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52fd7f4",
   "metadata": {},
   "source": [
    "## 3. Ridge Regression for 30s Delta\n",
    "\n",
    "The second baseline is a **regression** model that predicts the **30-second hot‑spot temperature change**, `delta_T_30s`.\n",
    "\n",
    "Problem setup:\n",
    "\n",
    "- We define the target column `delta_T_30s` as the difference between:\n",
    "  - the hot‑spot temperature **30 seconds in the future**, and  \n",
    "  - the **current** hot‑spot temperature.\n",
    "- Rows where the future value is not available (e.g., near the end of the time series) are naturally dropped.\n",
    "- We reuse the same `_mean` feature set as in the classification baseline, so both models operate on an identical input space.\n",
    "\n",
    "Model:\n",
    "\n",
    "- We use a **Ridge regression** pipeline:\n",
    "  - `StandardScaler` to normalize inputs,\n",
    "  - `Ridge(alpha=1.0)` as a simple L2‑regularized linear regressor.\n",
    "- L2 regularization shrinks coefficients and reduces overfitting, especially when features are correlated.\n",
    "\n",
    "Metrics:\n",
    "\n",
    "- We evaluate on the held‑out test split using:\n",
    "  - **MAE** (mean absolute error) in °C, which is easy to interpret as an average absolute miss in temperature,\n",
    "  - **RMSE** (root mean squared error) in °C, which penalizes large errors more strongly.\n",
    "- Together, MAE and RMSE give a first sense of how precise our short‑horizon temperature forecasts are.\n",
    "\n",
    "Again, this is only a **baseline**: later models (e.g., tree‑based or sequence models) should deliver lower MAE/RMSE on the same target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db398720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 4.669 °C\n",
      "RMSE: 9.270 °C\n"
     ]
    }
   ],
   "source": [
    "# Ridge regression baseline: 30 s temperature delta\n",
    "# - Use `delta_T_30s` as the continuous regression target.\n",
    "# - Construct train/test splits (chronological) for this target using the same feature set.\n",
    "# - Build a `Pipeline` consisting of `StandardScaler` + `Ridge(alpha=1.0)`.\n",
    "# - Fit the model on training data and predict on the held‑out test split.\n",
    "# - Compute MAE and RMSE in °C to quantify short‑horizon forecast error.\n",
    "\n",
    "reg_target = 'delta_T_30s'\n",
    "target_df = df.dropna(subset=feature_cols + [reg_target])\n",
    "split_idx_reg = int(len(target_df) * 0.8)\n",
    "train_reg = target_df.iloc[:split_idx_reg]\n",
    "test_reg = target_df.iloc[split_idx_reg:]\n",
    "\n",
    "X_train_reg = train_reg[feature_cols]\n",
    "X_test_reg = test_reg[feature_cols]\n",
    "y_train_reg = train_reg[reg_target]\n",
    "y_test_reg = test_reg[reg_target]\n",
    "\n",
    "reg = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', Ridge(alpha=1.0))\n",
    "])\n",
    "reg.fit(X_train_reg, y_train_reg)\n",
    "pred_reg = reg.predict(X_test_reg)\n",
    "\n",
    "mae = mean_absolute_error(y_test_reg, pred_reg)\n",
    "rmse = mean_squared_error(y_test_reg, pred_reg) ** 0.5\n",
    "print(f'MAE: {mae:.3f} °C')\n",
    "print(f'RMSE: {rmse:.3f} °C')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f8477b",
   "metadata": {},
   "source": [
    "## 4. Next Steps\n",
    "- Persist trained pipelines (`joblib.dump`) under `models/baseline/`.\n",
    "- Explore hyperparameter sweeps and alternate algorithms (tree-based, sequential) for Milestone 4.\n",
    "- Integrate scripts into automation to track metrics across commits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9908cc79",
   "metadata": {},
   "source": [
    "### 5. Automation & Metrics\n",
    "- The Makefile `baseline` target runs these data prep + training steps and saves models under `models/baseline/`.\n",
    "- `metrics/logreg_metrics.json` and `metrics/ridge_metrics.json` capture the latest ROC AUC / MAE history every time the training CLIs run.\n",
    "- CI (`.github/workflows/baseline.yml`) executes `make baseline`, `make test`, and `make infer` on each push/PR, so notebook results match the automated pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
